{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math 456 Project: Sentiment Analysis of Covid-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The training data contains 5000 labeled tweets while \n",
    "the released validation data have 2500 pieces of unlabeled tweets. \n",
    "\n",
    "The training data have 3 columns, containing Tweet ID, Tweet text, and labels.\n",
    "\n",
    "Note that the orders are shown as \n",
    "\n",
    "- Optimistic (0), \n",
    "- Thankful (1), \n",
    "- Empathetic (2),\n",
    "- Pessimistic (3), \n",
    "- Anxious (4), \n",
    "- Sad (5), \n",
    "- Annoyed (6), \n",
    "- Denial (7), \n",
    "- Surprise (8), \n",
    "- Official report (9),\n",
    "- Joking (10). \n",
    "\n",
    "For example, if the labels are 3 and 6, \n",
    "it means that this piece of the tweet is labeled as Pessimistic and Annoyed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Build a mathematical model for sentiment analysis via tweets. \n",
    "You may want to test your prediction of sentiments by using the validation dataset. \n",
    "However, notice that the validation dataset does not contain a score. \n",
    "You are recommended to use few lines (e.g. 50 lines) of the training set as the test data. \n",
    "You may first assign scores subjectively to tweets in the validation dataset \n",
    "and then compare the subjective scores with the predicted scores based on your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the data\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "data = {}\n",
    "with open('training.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        # row contains fields: ID, Tweet, Labels\n",
    "        data[row['ID']] = [row['Tweet'], row['Labels']]\n",
    "\n",
    "tweets, labels = np.transpose([data[k] for k in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning definition\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){ }\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() \n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "    text = BAD_SYMBOLS_RE.sub('', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x, y split\n",
    "x = tweets\n",
    "y = []\n",
    "for label in labels:\n",
    "    label_vector = [1 if (str(i) in label.split(\" \")) else 0 for i in range(11)]\n",
    "    y.append(label_vector)\n",
    "\n",
    "# train-test split\n",
    "cutoff = 50\n",
    "x_train = x[cutoff:]\n",
    "y_train = y[cutoff:]\n",
    "x_test = x[:cutoff]\n",
    "y_test = y[:cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: len(category)=1180\n",
      "1: len(category)=244\n",
      "2: len(category)=186\n",
      "3: len(category)=620\n",
      "4: len(category)=842\n",
      "5: len(category)=1088\n",
      "6: len(category)=1725\n",
      "7: len(category)=314\n",
      "8: len(category)=604\n",
      "9: len(category)=914\n",
      "10: len(category)=2257\n"
     ]
    }
   ],
   "source": [
    "# data exploration\n",
    "\n",
    "categories = [[] for _ in range(11)]\n",
    "for xval, labels in zip(x, y):\n",
    "    for i, yval in enumerate(labels):\n",
    "        if(yval == 1):\n",
    "            categories[i].append(xval)\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    print(f\"{i}: {len(category)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(preprocessor=<function clean_text at 0x000002057AC97940>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use sklearn's naive bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "\n",
    "model = Pipeline([\n",
    "        ('vect', CountVectorizer(preprocessor=clean_text)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier())),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# model = Pipeline([\n",
    "#         ('vect', CountVectorizer(preprocessor=clean_text)),\n",
    "#         ('tfidf', TfidfTransformer()),\n",
    "#         ('clf', ClassifierChain(RandomForestClassifier(), order='random', random_state=0)),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# ClassifierChain(base_lr, order='random', random_state=0)\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = model.predict(x_test)\n",
    "predictions_train = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions from model probabilities\n",
    "def preds_from_probs(probs):\n",
    "    # probs == one for each class, one for each output, false vs true\n",
    "    predictions = []\n",
    "    for output_i in range(len(probs[0])):\n",
    "        output_probs = [cls[output_i][1] for cls in probs]\n",
    "        converted = [1 if p > 0.5 else 0 for p in output_probs]\n",
    "        if all(p == 0 for p in converted):\n",
    "            # find best index\n",
    "            best_index = 0\n",
    "            for i, p in enumerate(output_probs):\n",
    "                if p > output_probs[best_index]:\n",
    "                    best_index = i\n",
    "            if output_probs[best_index] != 0:\n",
    "                converted[best_index] = 1\n",
    "            else:\n",
    "                # use random\n",
    "                converted[random.choice(range(len(converted)))] = 1\n",
    "        predictions.append(converted)\n",
    "    return predictions\n",
    "\n",
    "probs_test = model.predict_proba(x_test)\n",
    "probs_train = model.predict_proba(x_train)\n",
    "\n",
    "prob_pred_test = preds_from_probs(probs_test)\n",
    "prob_pred_train = preds_from_probs(probs_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_correct=9/num_total=50 = 0.18\n",
      "num_correct=4896/num_total=4950 = 0.9890909090909091\n",
      "0.18 0.9890909090909091\n"
     ]
    }
   ],
   "source": [
    "# compare\n",
    "def arr_equal(a, b):\n",
    "    if (len(a) != len(b)):\n",
    "        return False\n",
    "    for x, y in zip(a, b):\n",
    "        if(x != y):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def get_labels(a):\n",
    "    return ','.join((str(i) for i, x in enumerate(a) if x == 1))\n",
    "\n",
    "def compare(predictions, actuals):\n",
    "    num_correct = 0\n",
    "    num_total = len(predictions)\n",
    "    assert(len(predictions) == len(actuals))\n",
    "    for pred, act in zip(predictions, actuals):\n",
    "        if arr_equal(pred, act):\n",
    "            num_correct += 1\n",
    "        # else:\n",
    "            # print(f\"{get_labels(pred)}::\\t::{get_labels(act)}\")\n",
    "            # print(get_labels(pred),\"\\t\", get_labels(act))\n",
    "            # print(pred, act)\n",
    "            # pass\n",
    "    print(f\"{num_correct=}/{num_total=} = {num_correct / num_total}\")\n",
    "    return num_correct / num_total\n",
    "\n",
    "correct_test = compare(predictions_test, y_test)\n",
    "correct_train = compare(predictions_train, y_train)\n",
    "print(correct_test, correct_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_correct=12/num_total=50 = 0.24\n",
      "num_correct=4896/num_total=4950 = 0.9890909090909091\n",
      "0.24 0.9890909090909091\n"
     ]
    }
   ],
   "source": [
    "correct_test = compare(prob_pred_test, y_test)\n",
    "correct_train = compare(prob_pred_train, y_train)\n",
    "print(correct_test, correct_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_correct=1/num_total=50 = 0.02\n",
      "num_correct=74/num_total=4950 = 0.01494949494949495\n",
      "0.02 0.01494949494949495\n"
     ]
    }
   ],
   "source": [
    "# baseline random classifier\n",
    "import random \n",
    "\n",
    "class RandomClassifier():\n",
    "    def train(self, y):\n",
    "        self.ylength = len(y)\n",
    "        frequencies = [0 for _ in range(len(y[0]))]\n",
    "        for labels in y:\n",
    "            for i, yval in enumerate(labels):\n",
    "                if(yval == 1):\n",
    "                    frequencies[i] += 1\n",
    "        self.frequencies = [f/len(y) for f in frequencies]\n",
    "\n",
    "    def predict(self, x):\n",
    "        predictions = []\n",
    "        for xval in x:\n",
    "            prediction = [1 if random.random() < f else 0 for f in self.frequencies]\n",
    "            predictions.append(prediction)\n",
    "        return predictions\n",
    "\n",
    "randmodel = RandomClassifier()\n",
    "randmodel.train(y_test)\n",
    "predictions_test_rand = randmodel.predict(x_test)\n",
    "predictions_train_rand = randmodel.predict(x_train)\n",
    "\n",
    "correct_test = compare(predictions_test_rand, y_test)\n",
    "correct_train = compare(predictions_train_rand, y_train)\n",
    "print(correct_test, correct_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fa2f031288032d1150eabdd1dfbeedc52b889896a559216330df5e5c1fb2cab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
