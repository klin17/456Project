{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math 456 Project: Sentiment Analysis of Covid-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The training data contains 5000 labeled tweets while \n",
    "the released validation data have 2500 pieces of unlabeled tweets. \n",
    "\n",
    "The training data have 3 columns, containing Tweet ID, Tweet text, and labels.\n",
    "\n",
    "Note that the orders are shown as \n",
    "\n",
    "- Optimistic (0), \n",
    "- Thankful (1), \n",
    "- Empathetic (2),\n",
    "- Pessimistic (3), \n",
    "- Anxious (4), \n",
    "- Sad (5), \n",
    "- Annoyed (6), \n",
    "- Denial (7), \n",
    "- Surprise (8), \n",
    "- Official report (9),\n",
    "- Joking (10). \n",
    "\n",
    "For example, if the labels are 3 and 6, \n",
    "it means that this piece of the tweet is labeled as Pessimistic and Annoyed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Build a mathematical model for sentiment analysis via tweets. \n",
    "You may want to test your prediction of sentiments by using the validation dataset. \n",
    "However, notice that the validation dataset does not contain a score. \n",
    "You are recommended to use few lines (e.g. 50 lines) of the training set as the test data. \n",
    "You may first assign scores subjectively to tweets in the validation dataset \n",
    "and then compare the subjective scores with the predicted scores based on your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the data\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "data = {}\n",
    "with open('training.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        # row contains fields: ID, Tweet, Labels\n",
    "        data[row['ID']] = [row['Tweet'], row['Labels']]\n",
    "\n",
    "tweets, labels = np.transpose([data[k] for k in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We probably want to examine the data\n",
    "# eg. find the distributions of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning definition\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){ }\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() \n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "    text = BAD_SYMBOLS_RE.sub('', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x, y split\n",
    "x = tweets\n",
    "y = []\n",
    "for label in labels:\n",
    "    label_vector = [1 if (str(i) in label.split(\" \")) else 0 for i in range(11)]\n",
    "    y.append(label_vector)\n",
    "\n",
    "# train-test split\n",
    "cutoff = 50\n",
    "x_train = x[cutoff:]\n",
    "y_train = y[cutoff:]\n",
    "x_test = x[:cutoff]\n",
    "y_test = y[:cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(preprocessor=<function clean_text at 0x000001855165DA60>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultiOutputClassifier(estimator=LogisticRegression()))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use sklearn's naive bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = Pipeline([\n",
    "        ('vect', CountVectorizer(preprocessor=clean_text)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(LogisticRegression())),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = model.predict(x_test)\n",
    "predictions_train = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16 0.20505050505050504\n"
     ]
    }
   ],
   "source": [
    "# compare\n",
    "def arr_equal(a, b):\n",
    "    if (len(a) != len(b)):\n",
    "        return False\n",
    "    for x, y in zip(a, b):\n",
    "        if(x != y):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def get_labels(a):\n",
    "    return ','.join((str(i) for i, x in enumerate(a) if x == 1))\n",
    "\n",
    "def compare(predictions, actuals):\n",
    "    num_correct = 0\n",
    "    num_total = len(predictions)\n",
    "    assert(len(predictions == len(actuals)))\n",
    "    for pred, act in zip(predictions, actuals):\n",
    "        if arr_equal(pred, act):\n",
    "            num_correct += 1\n",
    "        # else:\n",
    "            # print(f\"{get_labels(pred)}::\\t::{get_labels(act)}\")\n",
    "            # print(get_labels(pred),\"\\t\", get_labels(act))\n",
    "            # print(pred, act)\n",
    "            # pass\n",
    "    return num_correct / num_total\n",
    "\n",
    "correct_test = compare(predictions_test, y_test)\n",
    "correct_train = compare(predictions_train, y_train)\n",
    "print(correct_test, correct_train)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fa2f031288032d1150eabdd1dfbeedc52b889896a559216330df5e5c1fb2cab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
